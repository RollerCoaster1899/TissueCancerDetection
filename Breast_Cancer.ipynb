{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Um3SV3OZcHM"
      },
      "outputs": [],
      "source": [
        "# Installing dependencies\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMPFeUUaZ2mR"
      },
      "outputs": [],
      "source": [
        "# Importa los modulos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib .pyplot\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaIpgW9QZ2iK"
      },
      "outputs": [],
      "source": [
        "# Installing the kaggle library\n",
        "! pip install kaggle\n",
        "#Making a directory \n",
        "! mkdir ~/.kaggle\n",
        "# copy the \"kaggle.json\" \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# allocating the required permision for this file\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-D1OzJebUzH"
      },
      "outputs": [],
      "source": [
        "#download the dataset\n",
        "! kaggle datasets download uciml/breast-cancer-wisconsin-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpRg77oLcXFs"
      },
      "outputs": [],
      "source": [
        "!unzip /content/breast-cancer-wisconsin-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu4Vophrc5bS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVczVKSndFhJ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQFIEQhydKOg"
      },
      "outputs": [],
      "source": [
        "# Checking the total rows and columns\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5PKfWYVeWOj"
      },
      "outputs": [],
      "source": [
        "# Columns and data types\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_IW26tde99J"
      },
      "outputs": [],
      "source": [
        "#2nd way to check null values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5BFtdOAfnG7"
      },
      "outputs": [],
      "source": [
        "# Drop the column with all missing values\n",
        "df = df.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUa4TObrgc3w"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WUk-ScJggM8"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chm1tcSGgwpA"
      },
      "outputs": [],
      "source": [
        "# Count values of the column diagnosis \n",
        "df['diagnosis'].value_counts()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ixrYx9hv7r"
      },
      "outputs": [],
      "source": [
        "# Create a box plot of diagnosis cases\n",
        "sns.countplot(df['diagnosis'], label = 'count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7g7J3ssiuU0"
      },
      "outputs": [],
      "source": [
        "# Used for transforming values to 0 and 1 (Y values only)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LabelEncoder_Y = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf2zj6oCjC58"
      },
      "outputs": [],
      "source": [
        "# Categorical to Numerical\n",
        "df.iloc[:,1] = LabelEncoder_Y.fit_transform(df.iloc[:,1].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAfMAISMkji_"
      },
      "outputs": [],
      "source": [
        "# Displaying column 1 (\"diagnosis\") values (now 0 and 1)\n",
        "df.iloc[:,1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3PFhyfGky3O"
      },
      "outputs": [],
      "source": [
        "# Creation of pairplot (correlation of several variables)\n",
        "sns.pairplot(df.iloc[:,1:7], hue='diagnosis')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of a Heatmap of the correlation between several variables with the color scheme 'YlGnBu', data annotated and expression in percentage.\n",
        "sns.heatmap(df.iloc[:,1:11].corr(), cmap= 'YlGnBu', annot=True, fmt= '.0%')"
      ],
      "metadata": {
        "id": "VUNjI5k0m30k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scalling \n",
        "# Splitting the data Sets in dependent / independent\n",
        "# Independiente = x\n",
        "X = df.iloc[:,2:31].values\n",
        "# Dependiente = y\n",
        "Y = df.iloc[:,1].values"
      ],
      "metadata": {
        "id": "e6ER_eBBtrTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the set 80:20\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "FPH1HT8xu9Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "id": "0CopKLoATrvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento / Standardize features by removing the mean and scaling to unit variance.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "Qgq-j5XWwYjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate more models using lazypredict\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "LP_models,predictions = clf.fit(X_train, X_test, Y_train, Y_test)\n",
        "LP_models"
      ],
      "metadata": {
        "id": "aHQDIZZm6xVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LP_models)"
      ],
      "metadata": {
        "id": "kEfz2C2uSLru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For the creation of the graph to evaluate the models x = model name from modelsÂ´ variable names\n",
        "# https://seaborn.pydata.org/tutorial/color_palettes.html para cambiar el color\n",
        "# https://github.com/dataprofessor/python/blob/main/lazypredict.ipynb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.set_theme(style='whitegrid')\n",
        "ax = sns.barplot(x=LP_models.index, y=\"Accuracy\", data=LP_models, palette='flare')\n",
        "plt.xticks(rotation=90)"
      ],
      "metadata": {
        "id": "JhL0i_yyPgYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of the three types of model\n",
        "from sklearn import tree\n",
        "\n",
        "# Assumes binary yes/no classification response\n",
        "def models(X_train, Y_train):\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  log = LogisticRegression(random_state= 0)\n",
        "  log.fit(X_train, Y_train) \n",
        "\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree = DecisionTreeClassifier(criterion= 'entropy', random_state= 0)\n",
        "  tree.fit(X_train, Y_train)\n",
        "\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  forest = RandomForestClassifier(n_estimators= 10, criterion= 'entropy', random_state= 0)\n",
        "  forest.fit(X_train, Y_train)\n",
        "\n",
        "  print('The accuracy of the Logistic Regression: ', log.score(X_train, Y_train))\n",
        "  print('The accuracy of the Decision Regression: ', tree.score(X_train, Y_train))\n",
        "  print('The accuracy of the Random Regression: ', forest.score(X_train, Y_train))\n",
        "\n",
        "  return log, tree, forest\n"
      ],
      "metadata": {
        "id": "CawRpvpmxgrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function deployment \n",
        "model = models(X_train, Y_train)"
      ],
      "metadata": {
        "id": "UIz5JQac6NIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of the confusion matrix, to see how accurate it is at the time of the predictions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, model[0].predict(X_test))\n",
        "tp = cm[0][0]\n",
        "tn = cm[1][1]\n",
        "fp = cm[0][1]\n",
        "fn = cm[1][0]\n",
        "print(cm)\n",
        "print('Accuracy: ', (tp+tn)/(tp+tn+fp+fn))"
      ],
      "metadata": {
        "id": "VgPiayu6AW4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way of obtaining classification accuracy and score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for i in range(len(model)):\n",
        "  print('Model: ',i)\n",
        "  print(classification_report(Y_test, model[i].predict(X_test)))\n",
        "  print(accuracy_score(Y_test, model[i].predict(X_test)))\n",
        "  print()"
      ],
      "metadata": {
        "id": "dkuvAEsIHOgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Las predicciones del modelo vs las reales\n",
        "pred = model[2].predict(X_test)\n",
        "print('Our model prediction: ')\n",
        "print(pred)\n",
        "print()\n",
        "print('Actual prediction: ')\n",
        "print(Y_test)"
      ],
      "metadata": {
        "id": "WNXmUqSQJQZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_test)):\n",
        "  if pred[i] == Y_test[i]:\n",
        "    print(\"Correct\")\n",
        "  else:\n",
        "    print(\"False\")\n"
      ],
      "metadata": {
        "id": "RJKkqJqua4ZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
